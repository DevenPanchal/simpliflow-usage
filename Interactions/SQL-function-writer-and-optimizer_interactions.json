[
    {
        "entity": "agent",
        "name": "SQL Writer",
        "input": "Write a random complex SQL query",
        "feedback_augmentred_input": "Write a random complex SQL queryIf you respond like this  - ''' Of course. Here is a complex SQL query designed for a fictional e-commerce database.\n\nThis query answers a specific, multi-layered business question:\n\n**\"For each product category, identify the top 3 customers by total spending. For each of these top customers, display their rank in that category, their total spending in that category, their overall lifetime spending across all categories, the date of their first and last purchase in that category, and a calculated 'Power User Score' based on their purchase frequency and total items bought.\"**\n\n### Fictional Database Schema\n\nFirst, let's imagine the tables we're working with:\n\n*   `Customers(customer_id, customer_name, join_date)`\n*   `Product_Categories(category_id, category_name)`\n*   `Products(product_id, product_name, category_id, price)`\n*   `Orders(order_id, customer_id, order_date, status)`\n*   `Order_Items(order_item_id, order_id, product_id, quantity)`\n\n---\n\n### The Complex SQL Query\n\n```sql\nWITH\n  -- Step 1: Aggregate order item data to get spending per customer, per category.\n  -- This CTE forms the base for our analysis.\n  CustomerCategorySpend AS (\n    SELECT\n      o.customer_id,\n      p.category_id,\n      SUM(oi.quantity * p.price) AS total_spent_in_category,\n      SUM(oi.quantity) AS total_items_in_category,\n      COUNT(DISTINCT o.order_id) AS total_orders_in_category,\n      MIN(o.order_date) AS first_purchase_date,\n      MAX(o.order_date) AS last_purchase_date\n    FROM Order_Items AS oi\n    JOIN Orders AS o\n      ON oi.order_id = o.order_id\n    JOIN Products AS p\n      ON oi.product_id = p.product_id\n    WHERE\n      o.status = 'completed' -- Only consider completed orders\n    GROUP BY\n      o.customer_id,\n      p.category_id\n  ),\n\n  -- Step 2: Calculate the overall lifetime spending for each customer across all categories.\n  -- This is calculated separately to be joined back in.\n  CustomerLifetimeSpend AS (\n    SELECT\n      o.customer_id,\n      SUM(oi.quantity * p.price) AS total_lifetime_spend\n    FROM Order_Items AS oi\n    JOIN Orders AS o\n      ON oi.order_id = o.order_id\n    JOIN Products AS p\n      ON oi.product_id = p.product_id\n    WHERE\n      o.status = 'completed'\n    GROUP BY\n      o.customer_id\n  ),\n\n  -- Step 3: Rank customers within each category based on their spending.\n  -- Also, join the lifetime spend and calculate a custom 'Power User Score'.\n  RankedCustomers AS (\n    SELECT\n      ccs.customer_id,\n      ccs.category_id,\n      ccs.total_spent_in_category,\n      ccs.first_purchase_date,\n      ccs.last_purchase_date,\n      cls.total_lifetime_spend,\n      -- The window function to rank customers partitioned by category\n      RANK() OVER (\n        PARTITION BY ccs.category_id\n        ORDER BY ccs.total_spent_in_category DESC\n      ) AS customer_rank_in_category,\n      -- A calculated 'Power User Score'\n      -- Logic: (Total items bought * 1.5) + (Number of orders * 2.5)\n      -- This gives more weight to repeat purchases.\n      (\n        ccs.total_items_in_category * 1.5 + ccs.total_orders_in_category * 2.5\n      ) AS power_user_score\n    FROM CustomerCategorySpend AS ccs\n    JOIN CustomerLifetimeSpend AS cls\n      ON ccs.customer_id = cls.customer_id\n  )\n\n-- Final Step: Select the top 3 ranked customers from each category and join with\n-- dimension tables (Customers, Product_Categories) to get the names.\nSELECT\n  pc.category_name,\n  rc.customer_rank_in_category,\n  c.customer_name,\n  rc.total_spent_in_category,\n  rc.total_lifetime_spend,\n  rc.power_user_score,\n  rc.first_purchase_date,\n  rc.last_purchase_date\nFROM RankedCustomers AS rc\nJOIN Customers AS c\n  ON rc.customer_id = c.customer_id\nJOIN Product_Categories AS pc\n  ON rc.category_id = pc.category_id\nWHERE\n  rc.customer_rank_in_category <= 3\nORDER BY\n  pc.category_name ASC,\n  rc.customer_rank_in_category ASC;\n```\n\n### Why This Query is Complex\n\n1.  **Common Table Expressions (CTEs):** The query is broken down into three logical, sequential CTEs (`CustomerCategorySpend`, `CustomerLifetimeSpend`, `RankedCustomers`). This makes an otherwise unreadable query manageable and demonstrates good SQL structure.\n\n2.  **Multiple Joins:** It joins five different tables (`Order_Items`, `Orders`, `Products`, `Customers`, `Product_Categories`) across different stages of the query.\n\n3.  **Window Function:** It uses `RANK() OVER (PARTITION BY ... ORDER BY ...)` which is a powerful analytical function. It calculates a rank for each customer *within* their product category, resetting the rank for each new category. This is far more efficient than trying to achieve the same result with self-joins or correlated subqueries.\n\n4.  **Multiple Levels of Aggregation:**\n    *   The first CTE aggregates data at the `customer_id` and `category_id` level.\n    *   The second CTE aggregates at the `customer_id` level only.\n    *   The final result combines these different levels of granularity.\n\n5.  **Calculated Fields:** It creates a custom metric, `power_user_score`, using a `CASE` statement or, in this case, a direct mathematical formula, to derive new business insights from existing data.\n\n6.  **Sub-querying through CTEs:** The final `SELECT` statement queries the result of the `RankedCustomers` CTE, which itself is built upon the results of two other CTEs. This chaining is a common pattern in complex data analysis.\n\n7.  **Filtering on a Window Function Result:** The final `WHERE rc.customer_rank_in_category <= 3` clause filters the results based on the output of the `RANK()` function, a common and essential technique when you need the \"Top N per group\". ''',  Then my feedback would be ''' Just output the query. Nothing else. ''' If you respond like this  - ''' ```sql\nWITH TradePairs AS (\n  -- Step 1: Pair up BUY and SELL transactions for the same stock by the same user.\n  -- This assumes a FIFO (First-In, First-Out) logic for pairing.\n  -- We use row_number to create a unique key for joining buys and sells.\n  SELECT\n    trade_id,\n    user_id,\n    stock_id,\n    action,\n    price,\n    quantity,\n    trade_date,\n    ROW_NUMBER() OVER (PARTITION BY user_id, stock_id, action ORDER BY trade_date) as trade_seq\n  FROM\n    transactions\n), MatchedTrades AS (\n  -- Step 2: Join the BUY and SELL pairs to calculate profit/loss and holding period for each matched transaction.\n  SELECT\n    b.user_id,\n    s.stock_id,\n    st.sector_id,\n    (s.price - b.price) * b.quantity AS profit_loss,\n    EXTRACT(DAY FROM s.trade_date - b.trade_date) AS holding_days,\n    s.trade_date AS sell_date\n  FROM\n    TradePairs b\n  JOIN\n    TradePairs s ON b.user_id = s.user_id AND b.stock_id = s.stock_id AND b.trade_seq = s.trade_seq\n  JOIN\n    stocks st ON b.stock_id = st.stock_id\n  WHERE\n    b.action = 'BUY' AND s.action = 'SELL' AND s.trade_date > b.trade_date\n), UserSectorPerformance AS (\n  -- Step 3: Aggregate performance metrics for each user within each stock sector.\n  -- Calculate total profit, average holding period, and the standard deviation of profits as a risk measure.\n  SELECT\n    user_id,\n    sector_id,\n    SUM(profit_loss) AS total_sector_profit,\n    COUNT(*) AS num_sector_trades,\n    AVG(holding_days) AS avg_holding_period,\n    STDDEV_SAMP(profit_loss) AS profit_volatility -- A measure of risk\n  FROM\n    MatchedTrades\n  GROUP BY\n    user_id,\n    sector_id\n), MarketSectorAverages AS (\n    -- Step 4: Calculate the average profit per trade for the entire market in each sector.\n    -- This will be used to compare individual performance against the market.\n    SELECT\n        sector_id,\n        AVG(profit_loss) as avg_market_profit_per_trade,\n        COUNT(DISTINCT user_id) as active_traders_in_sector\n    FROM\n        MatchedTrades\n    GROUP BY\n        sector_id\n), RankedPerformance AS (\n    -- Step 5: Calculate a risk-adjusted return score, compare user profit to market average,\n    -- and rank users within each sector based on this score.\n    SELECT\n        usp.user_id,\n        usp.sector_id,\n        usp.total_sector_profit,\n        usp.num_sector_trades,\n        usp.avg_holding_period,\n        usp.profit_volatility,\n        msa.avg_market_profit_per_trade,\n        -- Calculate a risk-adjusted score. Higher is better. Avoid division by zero.\n        CASE\n            WHEN usp.profit_volatility > 0 THEN usp.total_sector_profit / usp.profit_volatility\n            ELSE 0\n        END AS risk_adjusted_return,\n        -- Lag function to find the profit of the next best competitor in the same sector.\n        LAG(usp.total_sector_profit, 1, 0) OVER (\n            PARTITION BY usp.sector_id\n            ORDER BY usp.total_sector_profit DESC\n        ) AS next_competitor_profit,\n        -- Rank users based on their risk-adjusted return.\n        DENSE_RANK() OVER (\n            PARTITION BY usp.sector_id\n            ORDER BY (CASE WHEN usp.profit_volatility > 0 THEN usp.total_sector_profit / usp.profit_volatility ELSE 0 END) DESC\n        ) AS sector_rank\n    FROM\n        UserSectorPerformance usp\n    JOIN\n        MarketSectorAverages msa ON usp.sector_id = msa.sector_id\n    WHERE\n        usp.num_sector_trades > 5 -- Filter out users with very few trades\n)\n-- Final Step: Select the top 3 ranked users per sector and join with dimension tables\n-- to get user and sector names. Display a comprehensive set of performance metrics.\nSELECT\n    s.sector_name,\n    rp.sector_rank,\n    u.username,\n    u.country,\n    rp.total_sector_profit,\n    (rp.total_sector_profit - rp.next_competitor_profit) AS profit_lead_over_next,\n    rp.risk_adjusted_return,\n    rp.num_sector_trades,\n    rp.avg_holding_period,\n    rp.profit_volatility,\n    rp.avg_market_profit_per_trade\nFROM\n    RankedPerformance rp\nJOIN\n    users u ON rp.user_id = u.user_id\nJOIN\n    sectors s ON rp.sector_id = s.sector_id\nWHERE\n    rp.sector_rank <= 3\nORDER BY\n    s.sector_name ASC,\n    rp.sector_rank ASC;\n\n``` ''',  Then my feedback would be ''' Don't even output the backticks and anything else. ''' ",
        "output": "WITH\n  EmployeeSales AS (\n    SELECT\n      e.employee_id,\n      e.department_id,\n      p.category_id,\n      oi.quantity * p.unit_price AS sale_value,\n      o.order_date,\n      LEAD(o.order_date, 1) OVER (\n        PARTITION BY\n          e.employee_id\n        ORDER BY\n          o.order_date\n      ) AS next_sale_date\n    FROM employees AS e\n    JOIN orders AS o\n      ON e.employee_id = o.employee_id\n    JOIN order_items AS oi\n      ON o.order_id = oi.order_id\n    JOIN products AS p\n      ON oi.product_id = p.product_id\n    WHERE\n      o.status = 'Shipped'\n  ),\n  EmployeePerformanceMetrics AS (\n    SELECT\n      employee_id,\n      department_id,\n      category_id,\n      SUM(sale_value) AS total_category_sales,\n      COUNT(*) AS num_category_sales,\n      AVG(\n        JULIANDAY(next_sale_date) - JULIANDAY(order_date)\n      ) AS avg_days_between_sales\n    FROM EmployeeSales\n    GROUP BY\n      employee_id,\n      department_id,\n      category_id\n  ),\n  DepartmentCategoryBenchmarks AS (\n    SELECT\n      department_id,\n      category_id,\n      AVG(total_category_sales) AS avg_dept_category_sales,\n      PERCENTILE_CONT(0.90) WITHIN GROUP (\n        ORDER BY\n          total_category_sales DESC\n      ) AS p90_dept_category_sales,\n      MIN(avg_days_between_sales) AS best_avg_days_between_sales\n    FROM EmployeePerformanceMetrics\n    GROUP BY\n      department_id,\n      category_id\n  ),\n  RankedEmployees AS (\n    SELECT\n      epm.employee_id,\n      epm.department_id,\n      epm.category_id,\n      epm.total_category_sales,\n      epm.num_category_sales,\n      epm.avg_days_between_sales,\n      dcb.avg_dept_category_sales,\n      dcb.p90_dept_category_sales,\n      (\n        epm.total_category_sales - dcb.avg_dept_category_sales\n      ) / NULLIF(STDDEV_SAMP(epm.total_category_sales) OVER (PARTITION BY epm.department_id, epm.category_id), 0) AS sales_z_score,\n      DENSE_RANK() OVER (\n        PARTITION BY\n          epm.department_id,\n          epm.category_id\n        ORDER BY\n          epm.total_category_sales DESC\n      ) AS sales_rank_in_category\n    FROM EmployeePerformanceMetrics AS epm\n    JOIN DepartmentCategoryBenchmarks AS dcb\n      ON epm.department_id = dcb.department_id\n      AND epm.category_id = dcb.category_id\n    WHERE\n      epm.num_category_sales > (\n        SELECT\n          AVG(num_category_sales) * 0.5\n        FROM EmployeePerformanceMetrics\n      )\n  )\nSELECT\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category,\n  e.first_name || ' ' || e.last_name AS employee_name,\n  e.hire_date,\n  re.total_category_sales,\n  re.avg_dept_category_sales,\n  CASE\n    WHEN re.total_category_sales > re.p90_dept_category_sales\n    THEN 'Top Performer (90th Percentile)'\n    WHEN re.total_category_sales > re.avg_dept_category_sales\n    THEN 'Above Average'\n    ELSE 'Below Average'\n  END AS performance_tier,\n  re.sales_z_score,\n  re.avg_days_between_sales\nFROM RankedEmployees AS re\nJOIN employees AS e\n  ON re.employee_id = e.employee_id\nJOIN departments AS d\n  ON re.department_id = d.department_id\nJOIN categories AS c\n  ON re.category_id = c.category_id\nWHERE\n  re.sales_rank_in_category <= 5\nORDER BY\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category;"
    },
    {
        "entity": "agent",
        "name": "Optimizer",
        "input": "Optimize the SQL query for better performance---WITH\n  EmployeeSales AS (\n    SELECT\n      e.employee_id,\n      e.department_id,\n      p.category_id,\n      oi.quantity * p.unit_price AS sale_value,\n      o.order_date,\n      LEAD(o.order_date, 1) OVER (\n        PARTITION BY\n          e.employee_id\n        ORDER BY\n          o.order_date\n      ) AS next_sale_date\n    FROM employees AS e\n    JOIN orders AS o\n      ON e.employee_id = o.employee_id\n    JOIN order_items AS oi\n      ON o.order_id = oi.order_id\n    JOIN products AS p\n      ON oi.product_id = p.product_id\n    WHERE\n      o.status = 'Shipped'\n  ),\n  EmployeePerformanceMetrics AS (\n    SELECT\n      employee_id,\n      department_id,\n      category_id,\n      SUM(sale_value) AS total_category_sales,\n      COUNT(*) AS num_category_sales,\n      AVG(\n        JULIANDAY(next_sale_date) - JULIANDAY(order_date)\n      ) AS avg_days_between_sales\n    FROM EmployeeSales\n    GROUP BY\n      employee_id,\n      department_id,\n      category_id\n  ),\n  DepartmentCategoryBenchmarks AS (\n    SELECT\n      department_id,\n      category_id,\n      AVG(total_category_sales) AS avg_dept_category_sales,\n      PERCENTILE_CONT(0.90) WITHIN GROUP (\n        ORDER BY\n          total_category_sales DESC\n      ) AS p90_dept_category_sales,\n      MIN(avg_days_between_sales) AS best_avg_days_between_sales\n    FROM EmployeePerformanceMetrics\n    GROUP BY\n      department_id,\n      category_id\n  ),\n  RankedEmployees AS (\n    SELECT\n      epm.employee_id,\n      epm.department_id,\n      epm.category_id,\n      epm.total_category_sales,\n      epm.num_category_sales,\n      epm.avg_days_between_sales,\n      dcb.avg_dept_category_sales,\n      dcb.p90_dept_category_sales,\n      (\n        epm.total_category_sales - dcb.avg_dept_category_sales\n      ) / NULLIF(STDDEV_SAMP(epm.total_category_sales) OVER (PARTITION BY epm.department_id, epm.category_id), 0) AS sales_z_score,\n      DENSE_RANK() OVER (\n        PARTITION BY\n          epm.department_id,\n          epm.category_id\n        ORDER BY\n          epm.total_category_sales DESC\n      ) AS sales_rank_in_category\n    FROM EmployeePerformanceMetrics AS epm\n    JOIN DepartmentCategoryBenchmarks AS dcb\n      ON epm.department_id = dcb.department_id\n      AND epm.category_id = dcb.category_id\n    WHERE\n      epm.num_category_sales > (\n        SELECT\n          AVG(num_category_sales) * 0.5\n        FROM EmployeePerformanceMetrics\n      )\n  )\nSELECT\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category,\n  e.first_name || ' ' || e.last_name AS employee_name,\n  e.hire_date,\n  re.total_category_sales,\n  re.avg_dept_category_sales,\n  CASE\n    WHEN re.total_category_sales > re.p90_dept_category_sales\n    THEN 'Top Performer (90th Percentile)'\n    WHEN re.total_category_sales > re.avg_dept_category_sales\n    THEN 'Above Average'\n    ELSE 'Below Average'\n  END AS performance_tier,\n  re.sales_z_score,\n  re.avg_days_between_sales\nFROM RankedEmployees AS re\nJOIN employees AS e\n  ON re.employee_id = e.employee_id\nJOIN departments AS d\n  ON re.department_id = d.department_id\nJOIN categories AS c\n  ON re.category_id = c.category_id\nWHERE\n  re.sales_rank_in_category <= 5\nORDER BY\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category;---",
        "feedback_augmentred_input": "Optimize the SQL query for better performance---WITH\n  EmployeeSales AS (\n    SELECT\n      e.employee_id,\n      e.department_id,\n      p.category_id,\n      oi.quantity * p.unit_price AS sale_value,\n      o.order_date,\n      LEAD(o.order_date, 1) OVER (\n        PARTITION BY\n          e.employee_id\n        ORDER BY\n          o.order_date\n      ) AS next_sale_date\n    FROM employees AS e\n    JOIN orders AS o\n      ON e.employee_id = o.employee_id\n    JOIN order_items AS oi\n      ON o.order_id = oi.order_id\n    JOIN products AS p\n      ON oi.product_id = p.product_id\n    WHERE\n      o.status = 'Shipped'\n  ),\n  EmployeePerformanceMetrics AS (\n    SELECT\n      employee_id,\n      department_id,\n      category_id,\n      SUM(sale_value) AS total_category_sales,\n      COUNT(*) AS num_category_sales,\n      AVG(\n        JULIANDAY(next_sale_date) - JULIANDAY(order_date)\n      ) AS avg_days_between_sales\n    FROM EmployeeSales\n    GROUP BY\n      employee_id,\n      department_id,\n      category_id\n  ),\n  DepartmentCategoryBenchmarks AS (\n    SELECT\n      department_id,\n      category_id,\n      AVG(total_category_sales) AS avg_dept_category_sales,\n      PERCENTILE_CONT(0.90) WITHIN GROUP (\n        ORDER BY\n          total_category_sales DESC\n      ) AS p90_dept_category_sales,\n      MIN(avg_days_between_sales) AS best_avg_days_between_sales\n    FROM EmployeePerformanceMetrics\n    GROUP BY\n      department_id,\n      category_id\n  ),\n  RankedEmployees AS (\n    SELECT\n      epm.employee_id,\n      epm.department_id,\n      epm.category_id,\n      epm.total_category_sales,\n      epm.num_category_sales,\n      epm.avg_days_between_sales,\n      dcb.avg_dept_category_sales,\n      dcb.p90_dept_category_sales,\n      (\n        epm.total_category_sales - dcb.avg_dept_category_sales\n      ) / NULLIF(STDDEV_SAMP(epm.total_category_sales) OVER (PARTITION BY epm.department_id, epm.category_id), 0) AS sales_z_score,\n      DENSE_RANK() OVER (\n        PARTITION BY\n          epm.department_id,\n          epm.category_id\n        ORDER BY\n          epm.total_category_sales DESC\n      ) AS sales_rank_in_category\n    FROM EmployeePerformanceMetrics AS epm\n    JOIN DepartmentCategoryBenchmarks AS dcb\n      ON epm.department_id = dcb.department_id\n      AND epm.category_id = dcb.category_id\n    WHERE\n      epm.num_category_sales > (\n        SELECT\n          AVG(num_category_sales) * 0.5\n        FROM EmployeePerformanceMetrics\n      )\n  )\nSELECT\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category,\n  e.first_name || ' ' || e.last_name AS employee_name,\n  e.hire_date,\n  re.total_category_sales,\n  re.avg_dept_category_sales,\n  CASE\n    WHEN re.total_category_sales > re.p90_dept_category_sales\n    THEN 'Top Performer (90th Percentile)'\n    WHEN re.total_category_sales > re.avg_dept_category_sales\n    THEN 'Above Average'\n    ELSE 'Below Average'\n  END AS performance_tier,\n  re.sales_z_score,\n  re.avg_days_between_sales\nFROM RankedEmployees AS re\nJOIN employees AS e\n  ON re.employee_id = e.employee_id\nJOIN departments AS d\n  ON re.department_id = d.department_id\nJOIN categories AS c\n  ON re.category_id = c.category_id\nWHERE\n  re.sales_rank_in_category <= 5\nORDER BY\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category;---If you respond like this  - ''' Of course. This is an excellent, complex query that's perfect for optimization. It uses multiple CTEs, aggregations, and window functions, presenting several opportunities for performance improvement.\n\nHere is the optimized query, followed by a detailed breakdown of the changes and the reasoning behind them.\n\n### Optimized SQL Query\n\n```sql\n-- Optimized Query using pre-aggregation and efficient filtering\n\nWITH\n  -- Step 1: Pre-aggregate sales data at the order/category level.\n  -- This is the most significant optimization, drastically reducing rows for window functions.\n  OrderCategorySales AS (\n    SELECT\n      o.order_id,\n      o.employee_id,\n      p.category_id,\n      o.order_date,\n      SUM(oi.quantity * p.unit_price) AS category_sale_value\n    FROM orders AS o\n    JOIN order_items AS oi\n      ON o.order_id = oi.order_id\n    JOIN products AS p\n      ON oi.product_id = p.product_id\n    WHERE\n      o.status = 'Shipped'\n    GROUP BY\n      o.order_id,\n      o.employee_id,\n      p.category_id,\n      o.order_date\n  ),\n  -- Step 2: Calculate the time between sales for each employee using the pre-aggregated data.\n  EmployeeSaleFlow AS (\n    SELECT\n      ocs.employee_id,\n      ocs.category_id,\n      ocs.category_sale_value,\n      ocs.order_date,\n      LEAD(ocs.order_date, 1) OVER (\n        PARTITION BY\n          ocs.employee_id\n        ORDER BY\n          ocs.order_date\n      ) AS next_sale_date\n    FROM OrderCategorySales AS ocs\n  ),\n  -- Step 3: Calculate employee metrics and the global average for the filter in one pass.\n  EmployeePerformanceMetrics AS (\n    SELECT\n      esf.employee_id,\n      e.department_id,\n      esf.category_id,\n      SUM(esf.category_sale_value) AS total_category_sales,\n      COUNT(*) AS num_category_sales,\n      AVG(\n        JULIANDAY(esf.next_sale_date) - JULIANDAY(esf.order_date)\n      ) AS avg_days_between_sales,\n      -- Calculate the global average number of sales here to avoid a subquery later.\n      AVG(COUNT(*)) OVER () AS global_avg_num_sales\n    FROM EmployeeSaleFlow AS esf\n    JOIN employees AS e ON esf.employee_id = e.employee_id\n    GROUP BY\n      esf.employee_id,\n      e.department_id,\n      esf.category_id\n  ),\n  -- Step 4: Department benchmarks (largely unchanged, but now runs on a smaller dataset)\n  DepartmentCategoryBenchmarks AS (\n    SELECT\n      department_id,\n      category_id,\n      AVG(total_category_sales) AS avg_dept_category_sales,\n      PERCENTILE_CONT(0.90) WITHIN GROUP (\n        ORDER BY\n          total_category_sales DESC\n      ) AS p90_dept_category_sales\n    FROM EmployeePerformanceMetrics\n    GROUP BY\n      department_id,\n      category_id\n  ),\n  -- Step 5: Rank employees using the pre-calculated global average for efficient filtering.\n  RankedEmployees AS (\n    SELECT\n      epm.employee_id,\n      epm.department_id,\n      epm.category_id,\n      epm.total_category_sales,\n      epm.avg_days_between_sales,\n      dcb.avg_dept_category_sales,\n      dcb.p90_dept_category_sales,\n      (\n        epm.total_category_sales - dcb.avg_dept_category_sales\n      ) / NULLIF(STDDEV_SAMP(epm.total_category_sales) OVER (PARTITION BY epm.department_id, epm.category_id), 0) AS sales_z_score,\n      DENSE_RANK() OVER (\n        PARTITION BY\n          epm.department_id,\n          epm.category_id\n        ORDER BY\n          epm.total_category_sales DESC\n      ) AS sales_rank_in_category\n    FROM EmployeePerformanceMetrics AS epm\n    JOIN DepartmentCategoryBenchmarks AS dcb\n      ON epm.department_id = dcb.department_id\n      AND epm.category_id = dcb.category_id\n    -- This WHERE clause is now much more efficient.\n    WHERE\n      epm.num_category_sales > (epm.global_avg_num_sales * 0.5)\n  )\n-- Final SELECT: Join with dimension tables to get descriptive names.\nSELECT\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category,\n  e.first_name || ' ' || e.last_name AS employee_name,\n  e.hire_date,\n  re.total_category_sales,\n  re.avg_dept_category_sales,\n  CASE\n    WHEN re.total_category_sales > re.p90_dept_category_sales\n    THEN 'Top Performer (90th Percentile)'\n    WHEN re.total_category_sales > re.avg_dept_category_sales\n    THEN 'Above Average'\n    ELSE 'Below Average'\n  END AS performance_tier,\n  re.sales_z_score,\n  re.avg_days_between_sales\nFROM RankedEmployees AS re\nJOIN employees AS e\n  ON re.employee_id = e.employee_id\nJOIN departments AS d\n  ON re.department_id = d.department_id\nJOIN categories AS c\n  ON re.category_id = c.category_id\nWHERE\n  re.sales_rank_in_category <= 5\nORDER BY\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category;\n```\n\n---\n\n### Key Optimizations and Explanation\n\nHere\u2019s a breakdown of the performance bottlenecks in the original query and how the optimized version addresses them.\n\n#### 1. Pre-aggregation to Reduce Data Volume (Most Important)\n\n*   **Problem:** The original query's first CTE, `EmployeeSales`, operated on a per-`order_item` basis. This means if an order had 10 items, there would be 10 rows. The `LEAD()` window function had to process this potentially massive number of rows, which is very inefficient in terms of memory and CPU.\n*   **Solution:** I introduced a new first CTE, `OrderCategorySales`. This CTE aggregates the data from the `order_items` and `products` tables up to the `order_id`, `employee_id`, and `category_id` level *before* any window functions are applied.\n*   **Impact:** This dramatically reduces the number of rows passed to the subsequent CTEs. Instead of processing every single sale item, the `LEAD()` function now only processes one row per category within each order. This is the single biggest performance gain.\n\n#### 2. Eliminating the Inefficient Subquery in `WHERE` Clause\n\n*   **Problem:** The `RankedEmployees` CTE contained this filter: `WHERE epm.num_category_sales > (SELECT AVG(num_category_sales) * 0.5 FROM EmployeePerformanceMetrics)`. A subquery in a `WHERE` clause like this can be very slow. Depending on the database optimizer, it might be re-executed for every row, forcing a full scan of the `EmployeePerformanceMetrics` result set repeatedly.\n*   **Solution:** The value `AVG(num_category_sales)` is a constant across the entire dataset. We can calculate this value just once. I did this by adding a window function without a `PARTITION BY` clause in the `EmployeePerformanceMetrics` CTE: `AVG(COUNT(*)) OVER () AS global_avg_num_sales`. This efficiently calculates the global average and attaches it to every row.\n*   **Impact:** The `WHERE` clause in `RankedEmployees` is transformed into a simple comparison between two columns (`epm.num_category_sales > (epm.global_avg_num_sales * 0.5)`), eliminating the expensive and repeated subquery execution.\n\n#### 3. Logical Restructuring of CTEs\n\n*   **Problem:** The original query mixed data preparation (`LEAD` function) and aggregation in ways that could be streamlined. The `employees` table was joined very early, carrying the `department_id` through the large `EmployeeSales` CTE, which isn't strictly necessary until the main aggregation step.\n*   **Solution:** The optimized query has a more logical flow:\n    1.  `OrderCategorySales`: Aggregate raw transaction data.\n    2.  `EmployeeSaleFlow`: Focus solely on calculating the `next_sale_date` using the `LEAD` function on the smaller, pre-aggregated dataset.\n    3.  `EmployeePerformanceMetrics`: Join `employees` to get `department_id` just when it's needed for the `GROUP BY`, and perform all employee-level aggregations.\n*   **Impact:** This separation of concerns makes the query easier to read and can help the database query planner generate a more optimal execution plan by working with smaller, more focused intermediate result sets.\n\n### Indexing Strategy for Optimal Performance\n\nEven with a rewritten query, performance is highly dependent on proper indexing. To support this optimized query, you should ensure the following indexes exist:\n\n```sql\n-- For joins and filtering in the first CTE\nCREATE INDEX idx_orders_status_date ON orders (status, order_date);\nCREATE INDEX idx_orders_employee_id ON orders (employee_id);\nCREATE INDEX idx_order_items_order_id ON order_items (order_id);\nCREATE INDEX idx_order_items_product_id ON order_items (product_id);\n\n-- For joins to dimension tables (Primary Keys are usually indexed, but ensure they are)\nCREATE INDEX idx_employees_employee_id ON employees (employee_id);\nCREATE INDEX idx_products_product_id ON products (product_id);\nCREATE INDEX idx_departments_department_id ON departments (department_id);\nCREATE INDEX idx_categories_category_id ON categories (category_id);\n```\n\n*   `idx_orders_status_date`: Crucial for quickly finding `'Shipped'` orders and helps with the `ORDER BY` clause inside the `LEAD` function.\n*   Indexes on foreign key columns (`orders.employee_id`, `order_items.order_id`, etc.) are essential for fast JOIN performance. ''',  Then my feedback would be ''' all else is good but just output the sql. Not even the backticks ''' ",
        "output": "WITH\n  OrderCategorySales AS (\n    -- Step 1: Pre-aggregate sales to the order/category level.\n    -- This drastically reduces the number of rows for the LEAD window function.\n    SELECT\n      o.order_id,\n      o.employee_id,\n      p.category_id,\n      o.order_date,\n      SUM(oi.quantity * p.unit_price) AS category_sale_value\n    FROM orders AS o\n    JOIN order_items AS oi\n      ON o.order_id = oi.order_id\n    JOIN products AS p\n      ON oi.product_id = p.product_id\n    WHERE\n      o.status = 'Shipped'\n    GROUP BY\n      o.order_id,\n      o.employee_id,\n      p.category_id,\n      o.order_date\n  ),\n  EmployeeSaleFlow AS (\n    -- Step 2: Calculate next sale date on the smaller, pre-aggregated dataset.\n    SELECT\n      ocs.employee_id,\n      ocs.category_id,\n      ocs.category_sale_value,\n      ocs.order_date,\n      LEAD(ocs.order_date, 1) OVER (\n        PARTITION BY\n          ocs.employee_id\n        ORDER BY\n          ocs.order_date\n      ) AS next_sale_date\n    FROM OrderCategorySales AS ocs\n  ),\n  EmployeePerformanceMetrics AS (\n    -- Step 3: Aggregate employee metrics and calculate the global average for filtering in one pass.\n    SELECT\n      esf.employee_id,\n      e.department_id,\n      esf.category_id,\n      SUM(esf.category_sale_value) AS total_category_sales,\n      COUNT(*) AS num_category_sales,\n      AVG(\n        JULIANDAY(esf.next_sale_date) - JULIANDAY(esf.order_date)\n      ) AS avg_days_between_sales,\n      -- Calculate the global average to eliminate the expensive subquery later.\n      AVG(COUNT(*)) OVER () AS global_avg_num_sales\n    FROM EmployeeSaleFlow AS esf\n    JOIN employees AS e\n      ON esf.employee_id = e.employee_id\n    GROUP BY\n      esf.employee_id,\n      e.department_id,\n      esf.category_id\n  ),\n  DepartmentCategoryBenchmarks AS (\n    -- Step 4: Calculate department-level benchmarks. This now runs on a smaller result set.\n    SELECT\n      department_id,\n      category_id,\n      AVG(total_category_sales) AS avg_dept_category_sales,\n      PERCENTILE_CONT(0.90) WITHIN GROUP (\n        ORDER BY\n          total_category_sales DESC\n      ) AS p90_dept_category_sales\n    FROM EmployeePerformanceMetrics\n    GROUP BY\n      department_id,\n      category_id\n  ),\n  RankedEmployees AS (\n    -- Step 5: Calculate final ranks and scores, using the pre-calculated global average for efficient filtering.\n    SELECT\n      epm.employee_id,\n      epm.department_id,\n      epm.category_id,\n      epm.total_category_sales,\n      epm.avg_days_between_sales,\n      dcb.avg_dept_category_sales,\n      dcb.p90_dept_category_sales,\n      (\n        epm.total_category_sales - dcb.avg_dept_category_sales\n      ) / NULLIF(STDDEV_SAMP(epm.total_category_sales) OVER (PARTITION BY epm.department_id, epm.category_id), 0) AS sales_z_score,\n      DENSE_RANK() OVER (\n        PARTITION BY\n          epm.department_id,\n          epm.category_id\n        ORDER BY\n          epm.total_category_sales DESC\n      ) AS sales_rank_in_category\n    FROM EmployeePerformanceMetrics AS epm\n    JOIN DepartmentCategoryBenchmarks AS dcb\n      ON epm.department_id = dcb.department_id\n      AND epm.category_id = dcb.category_id\n    -- The subquery is replaced with a much more efficient column comparison.\n    WHERE\n      epm.num_category_sales > (epm.global_avg_num_sales * 0.5)\n  )\nSELECT\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category,\n  e.first_name || ' ' || e.last_name AS employee_name,\n  e.hire_date,\n  re.total_category_sales,\n  re.avg_dept_category_sales,\n  CASE\n    WHEN re.total_category_sales > re.p90_dept_category_sales\n    THEN 'Top Performer (90th Percentile)'\n    WHEN re.total_category_sales > re.avg_dept_category_sales\n    THEN 'Above Average'\n    ELSE 'Below Average'\n  END AS performance_tier,\n  re.sales_z_score,\n  re.avg_days_between_sales\nFROM RankedEmployees AS re\nJOIN employees AS e\n  ON re.employee_id = e.employee_id\nJOIN departments AS d\n  ON re.department_id = d.department_id\nJOIN categories AS c\n  ON re.category_id = c.category_id\nWHERE\n  re.sales_rank_in_category <= 5\nORDER BY\n  d.department_name,\n  c.category_name,\n  re.sales_rank_in_category;"
    }
]